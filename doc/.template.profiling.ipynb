{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling IMP applications {#mainpage}\n",
    "==========================\n",
    "\n",
    "[TOC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction {#introduction}\n",
    "\n",
    "In this tutorial we will look at CPU profiling of IMP code using\n",
    "Google's [gperftools](https://github.com/gperftools/gperftools) package.\n",
    "This will show us where time is being spent during a modeling run, so that\n",
    "we know where to focus our efforts in optimizing or otherwise improving the\n",
    "code.\n",
    "\n",
    "In this text we follow\n",
    "[Google's own documentation](https://htmlpreview.github.io/?https://github.com/gperftools/gperftools/blob/master/docs/cpuprofile.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites {#prereq}\n",
    "\n",
    "First, we need to install\n",
    "[gperftools](https://github.com/gperftools/gperftools). It can be compiled\n",
    "from source code, but it is generally easier to install a prebuilt package\n",
    "for it. We recommend running it on a Linux box, although it should also work\n",
    "on a Mac. To install on a Linux box, use something like\n",
    "\n",
    "    sudo dnf install pprof gperftools-libs\n",
    "\n",
    "On a Mac with [Homebrew](https://brew.sh), use\n",
    "\n",
    "    brew install gperftools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile IMP from source {#compile}\n",
    "\n",
    "Next, we need to build %IMP from source code. See the\n",
    "[installation instructions in the manual](@ref installation_source) for\n",
    "more details. In order to use gperftools the %IMP libraries should be linked\n",
    "against the profiler library (`-lprofiler`). This should be set up automatically\n",
    "when you run `cmake`. If not, you can manually add this linkage by adding\n",
    "something like `-DCMAKE_LD_FLAGS=\"-lprofiler\"` to your `cmake` invocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run application and collect profiling info {#run}\n",
    "\n",
    "There are several ways to collect profiling information; see the\n",
    "[gperftools documentation](https://htmlpreview.github.io/?https://github.com/gperftools/gperftools/blob/master/docs/cpuprofile.html)\n",
    "for more details. In this case, we simply collect profiling information for\n",
    "the entire process by setting the `CPUPROFILE` environment variable to the\n",
    "name of a profile output file. For this demonstration, we'll profile the\n",
    "modeling script from the [RNAPII PMI tutorial](https://integrativemodeling.org/tutorials/rnapolii_stalk/) by running something like the following from a\n",
    "terminal window:\n",
    "\n",
    "    git clone https://github.com/salilab/imp_tutorial.git\n",
    "    cd imp_tutorial/rnapolii/modeling\n",
    "    env CPUPROFILE=out.prof ~/imp/release/setup_environment.sh python modeling.py --test\n",
    "\n",
    "(This assumes that our IMP source code checkout is in `~/imp/release/`; alter\n",
    "the path appropriately if it is in a different directory.)\n",
    "\n",
    "Once the script completes, a file `out.prof` should be produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the profile {#analyze}\n",
    "\n",
    "Analysis of the profile can be done using the `pprof` tool.\n",
    "There are many ways to use this tool; see the\n",
    "[gperftools documentation](https://htmlpreview.github.io/?https://github.com/gperftools/gperftools/blob/master/docs/cpuprofile.html)\n",
    "for more details. A simple way to use it is to generate a PDF file and then\n",
    "view it in a PDF viewer:\n",
    "\n",
    "    pprof --pdf /usr/bin/python out.prof  > complete.pdf\n",
    "\n",
    "The resulting PDF can be [seen here](https://github.com/salilab/profiling_tutorial/blob/master/profiles/complete.pdf).\n",
    "This view can be rather overwhelming, since it shows every function (in IMP\n",
    "itself, but also in the Python interpreter and in the system libraries) that\n",
    "was responsible for a significant chunk of the program's runtime. Each node\n",
    "in the graph shows the name of the function, the percentage of total runtime\n",
    "that was spent in the body of this function itself, and the percentage of\n",
    "time that was spent both in the function and in other functions that it called.\n",
    "Edges in the graph point from calling functions to other functions that were\n",
    "called.\n",
    "\n",
    "In most cases it makes more sense to focus in on a subset of the program. For\n",
    "a typical application of IMP, a fixed setup is followed by a long sampling\n",
    "run where the majority of the CPU time is spent (in the\n",
    "function ``IMP::Optimizer::optimize``). Inspection of the\n",
    "[complete profile](https://github.com/salilab/profiling_tutorial/blob/main/profiles/complete.pdf)\n",
    "confirms that this is the case here too. We can make such a focused graph\n",
    "using the `--focus` option to `pprof`:\n",
    "\n",
    "    pprof --pdf --focus optimize /usr/bin/python out.prof  > optimize.pdf\n",
    "\n",
    "The resulting PDF can be [seen here](https://github.com/salilab/profiling_tutorial/blob/main/profiles/optimize.pdf).\n",
    "Let's zoom in on part of the graph:\n",
    "\n",
    "<img src=\"images/optimize-evaluate.png\" width=\"800px\" title=\"Profile optimize-evaluate\" />\n",
    "\n",
    "This shows us that evaluation of the scoring function\n",
    "(``IMP::ScoringFunction::evaluate``) is responsible for 99.1% of the runtime of\n",
    "the sampling. This confirms our expectation that applying Monte Carlo moves\n",
    "and applying the Monte Carlo acceptance criterion are fairly inexpensive\n",
    "operations. Of that time, roughly one third is spent in\n",
    "`before_protected_evaluate`, which does various per-scoring operations,\n",
    "such as updating the non-bonded list and ensuring constraints such as rigid\n",
    "bodies are satisfied, while the other two thirds is spent calculating\n",
    "restraint scores.\n",
    "\n",
    "Further inspection of the graph can reveal where significant time is being\n",
    "spent. This may be because the function is being called more times than is\n",
    "necessary, or because the function is inefficient and can be made faster.\n",
    "For example, in this case 20% of the entire runtime is spent in\n",
    "``IMP::core::RigidBody::update_members``, which sets the XYZ coordinates of each\n",
    "particle in a rigid body using the rigid body's orientation and the internal\n",
    "coordinates (relative to the body's reference frame). This is probably\n",
    "inefficient because this update is only necessary after a Monte Carlo move\n",
    "that affects a given rigid body, and the majority of moves do not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
